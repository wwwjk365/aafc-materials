---
title: "Introductions to pbdR"
output:
  revealjs::revealjs_presentation:
    theme: simple
    highlight: tango
    center: true
    smart: true
    incremental: true
---

## Batch Execution

- Running a serial R program in batch: 

```r
Rscript my_script.r 

R CMD BATCH my_script.R
```
- Running a parallel (with MPI) R program in batch

```r
mpirun -np 2 Rscript my_par_script.r
```

## Single Program/Multiple Data (SPMD)

- SPMD is arguably the simplest extension of serial programming
- Only one program is written, executed in batch on all processors
- Different processors are autonomous; there is no manager
- Dominant programming model for large machines for 30 years


## Introduction to pbdMPI

- MPI: Standard for managing communications (data and instructions) between different nodes/computers. 
- Implementations: OpenMPI, MPICH2, Cray MPT, ...
- Enables parallelism (via communication) on distributed machines
- Communicator: manages communications between processors 

---

The general process for directly — or indirectly — utilizing MPI in SPMD programs goes something like this: 

1. Initialize communicator(s). 
2. Have each process read in its portion of the data. 
3. Perform computations. 
4. Communicate results. 
5. Shut down the communicator(s).

## Let’s get our systems setup

## Basic Communicator Wrangling 

- Managing a Communicator:  Create and destroy communicators
    - `init()` Initialize communicator 
    - `finalize()` shut down communicator(s) 
- Rank query: Determine the processor’s position in the communicator
    -  `comm.rank()` “who am I?” 
    -  `comm.size()` “how many of us are there?” 
- Barrier: No processor can proceed until all processors can proceed
    - “computation wall” that only all processors together can tear down `barrier()`

## Simple pbdMIP Example

```r
library(pbdMPI, quietly = TRUE)
init()

myRank <- comm.rank() + 1 # comm index starts at 0, not 1
print(myRank)

finalize()
```
- Use `mpiexec -np 2 Rscript mpiex1.r` to run

---

## Your turn

- Try to print "Hello,world." on worker 0

```r
library(pbdMPI, quietly = TRUE)
init()

myRank <- comm.rank() 
if ( myRank == 0){
  print ("Hello,world.")
}

finalize()
```

## Reduce, Broadcast and Gather

- Reduction: Say each processor has a number `x.gbd`. Add all of them up, 
find the largest,find the smallest, ...
    - `reduce(x.gbd, op=’sum’)` - only one processor gets result (default is 0)
    - `allreduce(x.gbd, op=’sum’)` - every processor gets result
- Gather: Say each processor has a number. Create a new object on some processor(s)
containing all of those numbers.
    - `gather(x.gbd)` — only one processor gets result
    - `allgather(x.gbd)` — every processor gets result
- Broadcast: One processor has a number `x.gbd` that every other processor should also
have.
    - `bcast(x.gbd)`
