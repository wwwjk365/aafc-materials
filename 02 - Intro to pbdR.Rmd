---
title: "Introductions to pbdR"
output:
  revealjs::revealjs_presentation:
    theme: simple
    highlight: tango
    center: true
    smart: true
    incremental: true
---

## Batch Execution

- Running a serial R program in batch: 

```r
Rscript my_script.r 

R CMD BATCH my_script.R
```
- Running a parallel (with MPI) R program in batch

```r
mpirun -np 2 Rscript my_par_script.r
```

## Single Program/Multiple Data (SPMD)

- SPMD is arguably the simplest extension of serial programming
- Only one program is written, executed in batch on all processors
- Different processors are autonomous; there is no manager
- Dominant programming model for large machines for 30 years


## Introduction to pbdMPI

- MPI: Standard for managing communications (data and instructions) between different nodes/computers. 
- Implementations: OpenMPI, MPICH2, Cray MPT, ...
- Enables parallelism (via communication) on distributed machines
- Communicator: manages communications between processors 

---

The general process for directly — or indirectly — utilizing MPI in SPMD programs goes something like this: 

1. Initialize communicator(s). 
2. Have each process read in its portion of the data. 
3. Perform computations. 
4. Communicate results. 
5. Shut down the communicator(s).

## Let’s get our systems setup

## Basic Communicator Wrangling 

- Managing a Communicator:  Create and destroy communicators
    - `init()` Initialize communicator 
    - `finalize()` shut down communicator(s) 
- Rank query: Determine the processor’s position in the communicator
    -  `comm.rank()` “who am I?” 
    -  `comm.size()` “how many of us are there?” 
- Barrier: No processor can proceed until all processors can proceed
    - “computation wall” that only all processors together can tear down `barrier()`

## Simple pbdMIP Example

```r
library(pbdMPI, quietly = TRUE)
init()

myRank <- comm.rank() + 1 # comm index starts at 0, not 1
print(myRank)

finalize()
```
- Use `mpiexec -np 2 Rscript mpiex1.r` to run

---

## Your turn

- Try to print "Hello,world." on worker 0

```r
library(pbdMPI, quietly = TRUE)
init()

myRank <- comm.rank() 
if ( myRank == 0){
  print ("Hello,world.")
}

finalize()
```

## Reduce, Broadcast and Gather

- Reduction: Say each processor has a number `x.gbd`. Add all of them up, 
find the largest,find the smallest, ...
    - `reduce(x.gbd, op=’sum’)` - only one processor gets result (default is 0)
    - `allreduce(x.gbd, op=’sum’)` - every processor gets result
- Gather: Say each processor has a number. Create a new object on some processor(s)
containing all of those numbers.
    - `gather(x.gbd)` — only one processor gets result
    - `allgather(x.gbd)` — every processor gets result
- Broadcast: One processor has a number `x.gbd` that every other processor should also
have.
    - `bcast(x.gbd)`
    
    
## Example 2

```r
library(pbdMPI, quiet = TRUE)
init()
n.gbd <- sample(1:10, size = 1)
sm <- allreduce(n.gbd) # default op is ’sum’
print(sm)
gt <- allgather(n.gbd)
print(gt)
finalize()

```

- try run this example multiple times

## RNG Seeds

- Print: printing with control over which processor prints.
    - `comm.print(x, ...)`
    - `comm.cat(x, ...)`
- Random Seeds:
    - `comm.set.seed(seed, diff=FALSE)`: every processor uses the seed seed
    - `comm.set.seed(seed, diff=TRUE)`: every processor uses an independent seed (via `rlecuyer`)

---

```r
library(pbdMPI, quietly = TRUE)
init()

myRank <- comm.rank() 

comm.print("Hello, world")

finalize()
```

## Caution

- Only print *results*, not *computations*
- In short, printing stored objects is safe


## Apply, Lapply, and Sapply

- `pbdApply(X, MARGIN, FUN, ...)` — analogue of apply()
- `pbdLapply(X, FUN, ...)` — analogue of lapply()
- `pbdSapply(X, FUN, ...)` — analogue of sapply()

---

example

```r
library(pbdMPI, quiet = TRUE)
init()

n <- 100
x <- split((1:n) + n * comm.rank(), rep(1:10, each = 10))
sm <- pbdLapply(x, sum)
comm.print(unlist(sm))

finalize()
```

## Exercises

1. Write a script that will have each processor randomly take a sample of size 1 of TRUE and FALSE. Have each processor print its result.
2. Modify the script in Exercise 3-1 above to determine if any processors sampled TRUE. Do the same to determine if all processors sampled TRUE. In each case, print the result. Compare to the functions comm.all() and comm.any(). 
3. In pbdMPI, there is a parallel sorting function called comm.sort() which is similar to the usual sort() of R. Implement parallel equivalents to the usual order() and rank() of R.
